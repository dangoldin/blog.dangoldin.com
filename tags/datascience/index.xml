<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>datascience on Dan Goldin</title><link>/tags/datascience/</link><description>Recent content in datascience on Dan Goldin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 18 Nov 2016 00:00:00 +0000</lastBuildDate><atom:link href="/tags/datascience/index.xml" rel="self" type="application/rss+xml"/><item><title>Comparing the web requests made by the top sites: 2014 vs 2016</title><link>/2016/11/18/comparing-the-web-requests-made-by-the-top-sites-2014-vs-2016/</link><pubDate>Fri, 18 Nov 2016 00:00:00 +0000</pubDate><guid>/2016/11/18/comparing-the-web-requests-made-by-the-top-sites-2014-vs-2016/</guid><description>A few years ago I wrote a simple PhantomJS script to hit the top 100 Alexa domains and track how long it took to load as well as the types of requests it was making. The intent was to try to understand the different factors affecting site speed and how the different sites approached the problem. I rediscovered this script while digging through my old projects this week and thought it would be an interesting analysis to redo this analysis and see how it compared against the data from 2014.</description></item><item><title>Approachable data science</title><link>/2014/06/02/approachable-data-science/</link><pubDate>Mon, 02 Jun 2014 00:00:00 +0000</pubDate><guid>/2014/06/02/approachable-data-science/</guid><description>Data science has earned the reputation of being complicated and inaccessible to those without an advanced degree but it doesn&amp;rsquo;t have to be this way. The goal of data science is simply to unlock insights and value from data. There&amp;rsquo;s no need to make it more complicated than that. Of course, there are times where the data requires some domain knowledge or is just too big for someone without the necessary experience to work with but I believe that most places have enough low hanging fruit that anyone who can write a quick script can contribute and do data science.</description></item><item><title>Fun with the Oyster books API</title><link>/2014/03/16/fun-with-the-oyster-books-api/</link><pubDate>Sun, 16 Mar 2014 00:00:00 +0000</pubDate><guid>/2014/03/16/fun-with-the-oyster-books-api/</guid><description>I’m an avid reader and signed up for Oyster as soon as I discovered them. Since then, every time I wanted to read a new book my first step has been to check Oyster. If the book wasn’t available I’d get it the old fashioned way and read it via Readmill, another great app.
One feature I wish Oyster had was the ability to see the overlap between their available collection and what I had in my “to read” list.</description></item><item><title>Website load times: NYC vs Beijing</title><link>/2014/03/11/website-load-times-nyc-vs-beijing/</link><pubDate>Tue, 11 Mar 2014 00:00:00 +0000</pubDate><guid>/2014/03/11/website-load-times-nyc-vs-beijing/</guid><description>Over the weekend I wrote a quick script to crawl the top 100 Alexa sites and compare them against one another in terms of load times and resources being loaded. I shared my code on GitHub and earlier today I got a great pull request from rahimnathwani who ran the script in Beijing, using home ADSL, and wanted to share his dataset.
I suspected that that many sites were loading slowly for me due to my geographical distance from them and with this dataset we’re able to compare the load times between NYC and Beijing for these sites.</description></item><item><title>Examining the requests made by the top 100 sites</title><link>/2014/03/09/examining-the-requests-made-by-the-top-100-sites/</link><pubDate>Sun, 09 Mar 2014 00:00:00 +0000</pubDate><guid>/2014/03/09/examining-the-requests-made-by-the-top-100-sites/</guid><description>Since writing the Drowning in JavaScript post I’ve been meaning to take a stab at automating that analysis and seeing if I could generate some other insights. This weekend I finally got around to writing a quick PhantomJS script to load the top 100 Alexa sites and capture each of the linked resources as well as their type. The resulting data set contains the time it took the entire page to load as well as the content type for each of the linked files.</description></item><item><title>Heuristic vs algorithmic approaches</title><link>/2014/02/15/heuristic-vs-algorithmic-approaches/</link><pubDate>Sat, 15 Feb 2014 00:00:00 +0000</pubDate><guid>/2014/02/15/heuristic-vs-algorithmic-approaches/</guid><description>Something that’s come up frequently in my quantitative work is balancing heuristic and algorithmic approaches. It’s surprisingly difficult to get the first attempt at an algorithmic approach working properly - it’s not an academic exercise and real world issues will always appear. Over time I’ve found myself writing heuristic checks and tweaks to deal with the various edge cases the algorithmic approach encounters. For example, setting the min and max bounds on the results of a function or adjusting the slope of a curve if it ends up being set in the wrong direction.</description></item><item><title>Taxi pricing in NYC vs Mumbai</title><link>/2013/12/29/taxi-pricing-in-nyc-vs-mumbai/</link><pubDate>Sun, 29 Dec 2013 00:00:00 +0000</pubDate><guid>/2013/12/29/taxi-pricing-in-nyc-vs-mumbai/</guid><description>Something else that struck me during my trip to India was the difference in taxi fare between New York City and Mumbai. I expected them to be different but the magnitude of the difference was shocking. In NYC, the base fare is $2.50 and increases 50 cents for each additional 1/5th of a mile or 60 seconds of not moving. In Mumbai, the rate starts at 19 rupees (~32 cents) and includes the first 1.</description></item><item><title>Is Excel on a Mac intentionally hobbled?</title><link>/2013/11/09/is-excel-on-a-mac-intentionally-hobbled/</link><pubDate>Sat, 09 Nov 2013 00:00:00 +0000</pubDate><guid>/2013/11/09/is-excel-on-a-mac-intentionally-hobbled/</guid><description>The longer I’ve been involved in tech the fewer Windows laptops I’ve been seeing. It seems that to even be considered a startup you need to be giving your employees MacBooks. My conversion came years ago when I made the move from Linux in order to be able to run Excel since neither OpenOffice nor Google Spreadsheet were cutting it. Unfortunately, even after years of effort, I still can’t get to the same level of productivity as I had when using Windows during my consulting days.</description></item><item><title>In defense of Excel</title><link>/2013/09/20/in-defense-of-excel/</link><pubDate>Fri, 20 Sep 2013 00:00:00 +0000</pubDate><guid>/2013/09/20/in-defense-of-excel/</guid><description>Excel has developed a reputation of being bloated, slow, error prone and used primarily by &amp;ldquo;business people&amp;rdquo; who don&amp;rsquo;t have real quantitative skills. Just like anything else, Excel is a tool that can be misused but is significantly more useful than people give it credit for.
The most important benefit Excel provides is making data approachable and fun. By making it approachable Excel opens up data analysis to a ton of new people that come into it with their own experience and knowledge.</description></item><item><title>Programming and math</title><link>/2013/09/17/programming-and-math/</link><pubDate>Tue, 17 Sep 2013 00:00:00 +0000</pubDate><guid>/2013/09/17/programming-and-math/</guid><description>The tech world is conflicted about how much math a developer needs. Engineers working on quantitative systems or data science clearly require advanced math and there are also countless engineering roles where math is unnecessary. My experience is that even if you don’t use math, having a mathematical mindset makes you significantly more productive. You’re able to quickly estimate the complexity of various tasks and hone your intuition. You’re also able to quickly recognize patterns when refactoring, especially when working in a functional language.</description></item><item><title>Scraping Yahoo fantasy football stats with Scrapy</title><link>/2013/07/17/scraping-yahoo-fantasy-football-stats-with-scrapy/</link><pubDate>Wed, 17 Jul 2013 00:00:00 +0000</pubDate><guid>/2013/07/17/scraping-yahoo-fantasy-football-stats-with-scrapy/</guid><description>Last week, someone reminded me of an old project I had on GitHub that scraped fantasy football stats from Yahoo. Unfortunately, it was antiquated and failed to retrieve the data for the current season. I’ve also been interested in trying out the Scrapy framework and decided this would be a good opportunity to give it a shot. I tried finding a sample project that dealt with authentication as a starting point but wasn’t able to find one so hopefully my attempt can serve as an example to others.</description></item><item><title>An analysis of Lincoln's words</title><link>/2013/02/12/an-analysis-of-lincolns-words/</link><pubDate>Tue, 12 Feb 2013 00:00:00 +0000</pubDate><guid>/2013/02/12/an-analysis-of-lincolns-words/</guid><description>On Saturday, I finished Team of Rivals and while looking at my calendar noticed that it was also Lincoln&amp;rsquo;s birthday this week. What better way to celebrate his birthday than to analyze his speeches and letters? I downloaded the 7 volume set containing his speeches, letters, and essays from Project Gutenberg and spent a few hours on Sunday cleaning the text and writing a parsing script. On Monday, I started analyzing the text to see if I could make sense of it.</description></item><item><title>Identifying duplicate bills across states</title><link>/2013/02/05/identifying-duplicate-bills-across-states/</link><pubDate>Tue, 05 Feb 2013 00:00:00 +0000</pubDate><guid>/2013/02/05/identifying-duplicate-bills-across-states/</guid><description>This past weekend I participated in the Bicoastal Datafest hackathon that brought together journalists and hackers with the goal of analyzing money’s influence in politics. I came in with the idea of analyzing the evolution of a bill in order to see which politician made the various changes and relate that to campaign contributions. I quickly discovered that that wouldn&amp;rsquo;t be very easy, especially in two days, but I did meet Llewellyn, a journalist/hacker, who had a more practical idea of programmatically identifying bills across states that used the same language.</description></item><item><title>Making sense of my Twitter archive</title><link>/2013/01/19/making-sense-of-my-twitter-archive/</link><pubDate>Sat, 19 Jan 2013 00:00:00 +0000</pubDate><guid>/2013/01/19/making-sense-of-my-twitter-archive/</guid><description>I finally got access to my Twitter archive and decided to have some fun with it and also give me an excluse to play around with matplotlib. The first step was just seeing what the data looked like and what information was available. Turns out that Twitter included a simple HTML page to let you browse your tweets but also provided CSV files for each month. The fields were pretty self explanatory but one &amp;ldquo;gotcha&amp;rdquo; was needing to convert the timestamp to my local time.</description></item><item><title>Trend of actor vs actress age differences</title><link>/2012/05/23/trend-of-actor-vs-actress-age-differences/</link><pubDate>Wed, 23 May 2012 00:00:00 +0000</pubDate><guid>/2012/05/23/trend-of-actor-vs-actress-age-differences/</guid><description>I recently watched Miss Representation which documents how the portrayal of women in the media affects women’s roles in society. It raised many interesting points and definitely got me thinking. If you haven’t seen it already you should definitely check it out. One of the points was that there’s a huge pressure to cast female roles with young actresses whereas it doesn’t matter so much for the male. I was sure this was true but I wanted to see how big of a deal it actually was, take a coding break, and play around with some data.</description></item><item><title>What's the easiest way to be elected president?</title><link>/2009/01/21/whats-the-easiest-way-to-be-elected-president/</link><pubDate>Wed, 21 Jan 2009 00:00:00 +0000</pubDate><guid>/2009/01/21/whats-the-easiest-way-to-be-elected-president/</guid><description>Answer: Be elected for a first term, the second term will follow.
It turns out it&amp;rsquo;s pretty likely that a president will be elected to a second term. If we examine all previous Presidential Elections, we will see 8 presidents who failed to get reelected:
President Result Benjamin Harrison Failed to get reelected in 1892 George H. W. Bush Failed to get reelected in 1992 Herbert Hoover Failed to get reelected in 1932 Jimmy Carter Failed to get reelected in 1980 John Quincy Adams Failed to get reelected in 1828 Theodore Roosevelt Failed to get reelected in 1912 William Henry Harrison Failed to get elected in 1836 William Howard Taft Failed to get reelected in 1912 On the other hand, if we look at all presidents with 2 or more terms, we only see a few Presidents who have failed to get elected.</description></item><item><title>On weekend voting</title><link>/2008/10/24/on-weekend-voting/</link><pubDate>Fri, 24 Oct 2008 00:00:00 +0000</pubDate><guid>/2008/10/24/on-weekend-voting/</guid><description>I found an op-ed in the NY Times that claimed that the best way to increase voter turnout was by having election day fall on a weekend. They provide a few examples but nothing too detailed. I tried pulling in some data and seeing if I could come to the same conclusion. I used two data sets: voter turn out by country and election dates by country.
Combining this data into one table, and ignoring the missing data:</description></item></channel></rss>