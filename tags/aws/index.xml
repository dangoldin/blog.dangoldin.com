<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aws on Dan Goldin</title><link>/tags/aws/</link><description>Recent content in Aws on Dan Goldin</description><generator>Hugo</generator><language>en</language><lastBuildDate>Fri, 11 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/aws/index.xml" rel="self" type="application/rss+xml"/><item><title>Amazon owns more than $2B worth of IPV4 addresses</title><link>/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/</link><pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate><guid>/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/</guid><description>&lt;p>While listening to a &lt;a href="https://softwareengineeringdaily.com/2020/12/02/bgp-with-andree-toonk/">podcast discussing BGP&lt;/a> I heard the fact that AWS owns more than $2B worth of IP addresses. I knew AWS was massive but this came as a big shock so I decided to do some digging around. I came across a &lt;a href="https://ipv4marketgroup.com/ipv4-pricing/">site&lt;/a> that listed the market prices of IP addresses and the range looks to be anywhere from $20 to $30 per IP depending on the block size. Now it was time to figure out the IP addresses owned by Amazon. I figured this would be difficult but lucky for us AWS actually &lt;a href="https://ip-ranges.amazonaws.com/ip-ranges.json">publishes&lt;/a> their entire set of IP addresses as JSON.&lt;/p></description></item><item><title>Optimizing AWS reservations</title><link>/2020/07/08/optimizing-aws-reservations/</link><pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate><guid>/2020/07/08/optimizing-aws-reservations/</guid><description>&lt;p>The Information has &lt;a href="https://www.theinformation.com/articles/uber-ceo-wants-to-shift-more-engineering-jobs-to-india-sparking-internal-debate">an article&lt;/a> making the case that Uber was better off having their own data centers versus relying on the cloud given the impact of COVID but that would depend on their reservation strategy. Sure if they reserved AWS capacity then they would be on the hook. Alternatively, if they had no reservations and were running everything on demand they would have incurred higher previous costs but would immediately be able to shut things down. This got me thinking about the optimal reservation strategy - the reality is that this depends very much on your business and the ability to forecast but this is an interesting exercise in speculation.&lt;/p></description></item><item><title>AWS 101</title><link>/2020/06/19/aws-101/</link><pubDate>Fri, 19 Jun 2020 00:00:00 +0000</pubDate><guid>/2020/06/19/aws-101/</guid><description>&lt;p>Earlier this week I hosted an &amp;ldquo;AWS 101&amp;rdquo; session at work. The goal was to give a small group an interactive introduction to the primary AWS services over 90 minutes. I figure I&amp;rsquo;d share our agenda and exercises in case they&amp;rsquo;re helpful to anyone else. We had trouble sticking to the times but the fact that everyone was remote did make it easier to do group-debugging with those stuck sharing their screens.&lt;/p></description></item><item><title>AWS EC2 instance arbitrage</title><link>/2016/03/05/aws-ec2-instance-arbitrage/</link><pubDate>Sat, 05 Mar 2016 00:00:00 +0000</pubDate><guid>/2016/03/05/aws-ec2-instance-arbitrage/</guid><description>&lt;p>While reserving some EC2 instances earlier this week I discovered that Amazon allows you to &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-buying-guide.html">sell&lt;/a> reserved instances you’re no longer using. Usually the prices the third parties are offering are very close to the fair market value but I wondered if there was an arbitrage opportunity by reserving a longer term instance and selling it for a series of shorter term leases. The &lt;a href="https://aws.amazon.com/ec2/pricing/">typical discount&lt;/a> for buying a 1 year reserved instance is 30% while buying one for 3 years can get over 60%. The idea being that if you can get an instance for a 60% discount over 3 years and then sell it for 3 one year terms at a 25% discount you end up coming out ahead. Of course the challenge is that Amazon constantly drops prices so a 60% discount now may be equivalent to something much smaller three years later. There’s also the risk of no one purchasing your instances but that seems unlikely since you can always undercut Amazon’s official price. The other factor is the discount rate since you’re paying up front for 3 years worth of an instance. During that time you could have taken that money and invested it elsewhere which could have led to a better return but which would have been unlikely when you’re getting a 30% discount over the course of a year.&lt;/p></description></item><item><title>Symptom based monitoring</title><link>/2014/12/01/symptom-based-monitoring/</link><pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate><guid>/2014/12/01/symptom-based-monitoring/</guid><description>&lt;p>A month or so ago I read Rob Ewaschuk’s &lt;a href="https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/preview?sle=true" target="_blank">philosophy on alerting&lt;/a> and since then I’ve been trying to be more aware of the alerts we have and whether any can be improved. The most actionable insight was to start thinking in terms of “symptom-based monitoring” where the alerts should reflect what the users are experiencing rather than various issues along the tech stack. This aligns your alerts with user expectations and can also simplify alerting since they will all be running at a high level. It may take longer to diagnose what the underlying problem is but it will reduce the total number of alerts required.&lt;/p></description></item><item><title>AWS Glacier</title><link>/2014/10/12/aws-glacier/</link><pubDate>Sun, 12 Oct 2014 00:00:00 +0000</pubDate><guid>/2014/10/12/aws-glacier/</guid><description>&lt;p>I’ve been trying to reduce the amount of stuff I have and a big part of it is old electronics. I’ve been selling off old headphones and random cables but the one thing that’s been more difficult to get rid of is older hard drives. I know that most of the stuff on them is junk that I’ll never see again but it’s still tough to just throw it away. They’re reminders of previous jobs and old projects that are a part of my identity that are tough to permanently delete with a click. Many of them are unique in the world and only exist on an old hard drive. I realize it’s foolish to keep them around but it’s tough to let go.&lt;/p></description></item><item><title>AWS is about infrastructure optionality</title><link>/2014/03/30/aws-is-about-infrastructure-optionality/</link><pubDate>Sun, 30 Mar 2014 00:00:00 +0000</pubDate><guid>/2014/03/30/aws-is-about-infrastructure-optionality/</guid><description>&lt;img src="/image/aws-services.png" alt="AWS services" data-width="1107" data-height="383" data-layout="responsive" />
&lt;p>Every time Amazon announces a price drop there are always people pointing out that it’s still more expensive than other cloud computing services such as Linode or Digital Ocean. The Amazon fans then respond by saying sure AWS is more expensive but the value is the ability to scale quickly when needed.&lt;/p>
&lt;p>For me, the biggest value behind AWS is the ecosystem and the included optionality. When building large scale web services it’s tough to know every issue you will run into and more often than not your needs and implementation will change. AWS provides a ton of available tools that make growing and scaling easier beyond the hardware itself. You may start with using EC2 for your server and S3 for hosting your static assets but over time you may start using Cloudfront as a CDN and Redshift for your analytics and EMR to process your various logs. That’s the biggest value in AWS - not being able to launch new machines quickly but having a set of infrastructure options that can be specialized to fit your needs.&lt;/p></description></item><item><title>Developing on a remote instance</title><link>/2014/01/23/developing-on-a-remote-instance/</link><pubDate>Thu, 23 Jan 2014 00:00:00 +0000</pubDate><guid>/2014/01/23/developing-on-a-remote-instance/</guid><description>&lt;p>One of the first things I was given when joining &lt;a href="http://triplelift.com" target="_blank">TripleLift&lt;/a> was a Macbook Air and an Amazon EC2 instance to do my development work on. Before that, every company I worked at would give me a pretty powerful computer so that I’d be able to do my development work locally. At first, coding on a remote instance took some getting used to but now I&amp;rsquo;m a fan of this approach.&lt;/p></description></item><item><title>RDS and R</title><link>/2013/11/15/rds-and-r/</link><pubDate>Fri, 15 Nov 2013 00:00:00 +0000</pubDate><guid>/2013/11/15/rds-and-r/</guid><description>&lt;p>In my quest to replace Excel with R I’ve been spending the past week trying to do everything in R. It hasn’t been that easy with many things taking longer due to me having to reference the R docs but one thing that’s been great so far is being able to quickly run a query on Amazon’s RDS and pull data into a data frame for quick analysis. Being able to wrap this into a reusable function makes things even better. The one thing that makes it tricky was not being able to connect to RDS directly but having to tunnel through an EC2 instance. Below are the steps to replicate the setup.&lt;/p></description></item><item><title>Splitting an AWS account</title><link>/2013/08/24/splitting-an-aws-account/</link><pubDate>Sat, 24 Aug 2013 00:00:00 +0000</pubDate><guid>/2013/08/24/splitting-an-aws-account/</guid><description>&lt;p>When we launched &lt;a href="http://getpressi.com" target="_blank">Pressi&lt;/a>, I had it set up under my personal AWS account. Recently, we needed to move it into a separate AWS account and I wanted to share the steps to help others running into the same issue. Unsurprisingly, most of the effort went into planning and figuring out the migration steps and order in which they should be done. We weren’t able to eliminate downtime entirely but we reduced it as much as we could.&lt;/p></description></item><item><title>Mmmm... pseudo static sites</title><link>/2013/03/12/mmmm-pseudo-static-sites/</link><pubDate>Tue, 12 Mar 2013 00:00:00 +0000</pubDate><guid>/2013/03/12/mmmm-pseudo-static-sites/</guid><description>&lt;p>Reading &lt;a href="http://blog.apps.npr.org/2013/02/14/app-template-redux.html" target="_blank">Katie Zhu’s post&lt;/a> on NPR’s news app architecture got me curious about a setup where most of the content is static and can be hosted on S3 and EC2 is primarily used to generate the static content which is then uploaded to S3. The benefits were obvious:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Cost:&lt;/strong> S3 is cheaper than EC2.&lt;/li>
&lt;li>&lt;strong>Reliable:&lt;/strong> S3 doesn’t go down near as frequently as EC2.&lt;/li>
&lt;li>&lt;strong>Scalable:&lt;/strong> Since it’s primarily static you don’t have to worry about additional capacity or dealing with caching, databases, and all the other fun things.&lt;/li>
&lt;li>&lt;strong>Simpler:&lt;/strong> There are no weird server issues here. As long as you generate the right content and your rendering is good, you don’t need to worry about a web server acting up.&lt;/li>
&lt;/ul>
&lt;p>I’ve been meaning to write a script that would scrape Hacker News in order to show me the top content I missed while sleeping. I had some time this weekend and decided to give it a go using this “pseudo-static” approach. The result is called Yet Another Hacker News Reader (&lt;a href="http://yahnr.dangoldin.com/" target="_blank">YAHNR&lt;/a>) and you can take a look at the code on &lt;a href="https://github.com/dangoldin/yahnr" target="_blank">GitHub&lt;/a>. Turns out it was pretty simple to write and the most difficult part was thinking differently about the problem. Whereas I’d keep the content in a database I ended up storing them in static JSON files and instead of having the logic to generate the HTML page live on a web server I have it using Mustache templates.&lt;/p></description></item></channel></rss>