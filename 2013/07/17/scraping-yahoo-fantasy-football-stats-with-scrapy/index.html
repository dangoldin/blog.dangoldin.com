<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Scraping Yahoo fantasy football stats with Scrapy - Dan Goldin
</title><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=referrer content="no-referrer"><meta name=description content="Over the weekend I updated my old Yahoo fantasy football stats scraper to use Scrapy and wanted to share some thoughts."><meta property="og:site_name" content="Dan Goldin"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:url" content="/2013/07/17/scraping-yahoo-fantasy-football-stats-with-scrapy/"><meta property="og:title" content="Scraping Yahoo fantasy football stats with Scrapy"><meta property="og:image" content="/image/photo.jpg"><meta property="og:description" content="Over the weekend I updated my old Yahoo fantasy football stats scraper to use Scrapy and wanted to share some thoughts."><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@dangoldin"><meta name=twitter:creator content="@dangoldin"><meta name=twitter:title content="Scraping Yahoo fantasy football stats with Scrapy"><meta name=twitter:description content="Over the weekend I updated my old Yahoo fantasy football stats scraper to use Scrapy and wanted to share some thoughts."><meta name=twitter:image content="/image/photo.jpg"><link rel=canonical href=/2013/07/17/scraping-yahoo-fantasy-football-stats-with-scrapy/><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.2/css/bootstrap.min.css integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin=anonymous><link rel=stylesheet href=https://nanx-assets.netlify.app/fonts.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github-gist.min.css integrity="sha512-od7JLoOTxM8w/HSKGzP9Kexc20K9p/M2zxSWsd7H1e4Ctf+8SQFtCWEZnW5u6ul5ehSECa5QmOk9ju2nQMmlVA==" crossorigin=anonymous><link rel="shortcut icon" href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=UA-36313127-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-36313127-1")</script></head><body><div class="my-4 my-lg-5 header"><div class=container><div class=row><div class="col-auto offset-lg-2 d-none d-lg-block"><a href=/><img class="ml-lg-4 logo img-fluid d-block rounded-circle" src=/image/photo.jpg alt=logo></a></div><div class="col-auto align-self-center mr-auto"><a href=/><h1 class=name>Dan Goldin</h1></a><ul class="nav nav-primary"><li class=nav-item><a class="nav-link text-home" href=/>Home</a></li><li class=nav-item><a class="nav-link text-about" href=/about/>About</a></li><li class=nav-item><a class="nav-link text-lore" href=/lore/>Lore</a></li></ul></div></div></div></div><div class=content><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-lg-8"><h1 class="mx-0 mx-md-4 blog-post-title">Scraping Yahoo fantasy football stats with Scrapy</h1><div class="mb-md-4 meta"><span class="date middot" title='Wed Jul 17 2013 00:00:00 UTC'>2013-07-17
</span><span class="reading-time middot">4 min read</span><div class="d-none d-md-inline tags"><ul class="list-unstyled d-inline"><li class="d-inline middot"><a href=/tags/python>python</a></li><li class="d-inline middot"><a href=/tags/code>code</a></li><li class="d-inline middot"><a href=/tags/datascience>datascience</a></li></ul></div><div class="d-none d-md-inline tags"><ul class="list-unstyled d-inline"></ul></div></div><div class="markdown blog-post-content"><p>Last week, someone reminded me of an old project I had on GitHub that scraped fantasy football stats from Yahoo. Unfortunately, it was antiquated and failed to retrieve the data for the current season. I’ve also been interested in trying out the <a href=http://scrapy.org/ target=_blank>Scrapy</a> framework and decided this would be a good opportunity to give it a shot. I tried finding a sample project that dealt with authentication as a starting point but wasn’t able to find one so hopefully my attempt can serve as an example to others.</p><p>The full project is <a href=https://github.com/dangoldin/yahoo-ffl target=_blank>available on GitHub</a> but I wanted to highlight a few of the components:</p><ul class=bulleted><li><strong>parse method</strong>: This submits a form POST to the Yahoo login page which authenticates the session. The key point here is to specify a callback function which will continue the existing session.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parse</span>(self, response):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> [FormRequest<span style=color:#f92672>.</span>from_response(response,
</span></span><span style=display:flex><span>                formdata<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;login&#39;</span>: self<span style=color:#f92672>.</span>settings[<span style=color:#e6db74>&#39;YAHOO_USERNAME&#39;</span>],
</span></span><span style=display:flex><span>                		  <span style=color:#e6db74>&#39;passwd&#39;</span>: self<span style=color:#f92672>.</span>settings[<span style=color:#e6db74>&#39;YAHOO_PASSWORD&#39;</span>]},
</span></span><span style=display:flex><span>                callback<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>after_login)]</span></span></code></pre></div></li><li><strong>parse_stats method</strong>: In previous projects, I struggled with separating the crawling from the parsing since the page would have information that would relevant to both - for example I would want to extract information from a page as well as find the next page to scrape. Scrapy offers a nice solution by letting you return different types from the same method. Returing a Request will lead to another page being crawled but one can also returned the scraped structured data via an Item. In the case of the scraper, I return the fantasy football stats on each page via Items but also return a Request when I want to navigate to the next page of stats.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parse_stats</span>(self, response):
</span></span><span style=display:flex><span>    hxs <span style=color:#f92672>=</span> HtmlXPathSelector(response)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Parse the next url</span>
</span></span><span style=display:flex><span>    next_page <span style=color:#f92672>=</span> hxs<span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#39;//ul[@class=&#34;pagingnavlist&#34;]/li[contains(@class,&#34;last&#34;)]/a/@href&#39;</span>)
</span></span><span style=display:flex><span>    next_page_url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;http://football.fantasysports.yahoo.com&#39;</span> <span style=color:#f92672>+</span> next_page<span style=color:#f92672>.</span>extract()[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    count <span style=color:#f92672>=</span> int(RE_CNT<span style=color:#f92672>.</span>findall(next_page_url)[<span style=color:#ae81ff>0</span>]) <span style=color:#75715e># Don&#39;t go past a certain threshold of players</span>
</span></span><span style=display:flex><span>    current_week <span style=color:#f92672>=</span> int(RE_WEEK<span style=color:#f92672>.</span>findall(next_page_url)[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    self<span style=color:#f92672>.</span>log(<span style=color:#e6db74>&#39;Next url is at count </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> with week </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(count, current_week))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> current_week <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>17</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># Parse the stats</span>
</span></span><span style=display:flex><span>        stat_rows <span style=color:#f92672>=</span> hxs<span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#39;//table[@id=&#34;statTable0&#34;]/tbody/tr&#39;</span>)
</span></span><span style=display:flex><span>        xpath_map <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;name&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;player&#34;)]/div[contains(@class,&#34;ysf-player-name&#34;)]/a/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;position&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;player&#34;)]/div[contains(@class,&#34;ysf-player-detail&#34;)]/ul/li[contains(@class,&#34;ysf-player-team-pos&#34;)]/span/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;opp&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;opp&#34;)]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;passing_yds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][1]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;passing_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][2]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;passing_int&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][3]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;rushing_yds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][4]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;rushing_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][5]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;receiving_recs&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][6]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;receiving_yds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][7]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;receiving_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][8]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;return_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][9]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;misc_twopt&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][10]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;fumbles&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][11]/text()&#39;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;points&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;pts&#34;)]/text()&#39;</span>,
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> stat_row <span style=color:#f92672>in</span> stat_rows:
</span></span><span style=display:flex><span>            stats_item <span style=color:#f92672>=</span> ScrapefflPlayerItem()
</span></span><span style=display:flex><span>            stats_item[<span style=color:#e6db74>&#39;week&#39;</span>] <span style=color:#f92672>=</span> current_week
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> col_name, xpath <span style=color:#f92672>in</span> xpath_map<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>                stats_item[col_name] <span style=color:#f92672>=</span> stat_row<span style=color:#f92672>.</span>select(xpath)<span style=color:#f92672>.</span>extract()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> stats_item
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Jump to next week if we go past the threshold of players</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> count <span style=color:#f92672>&gt;</span> self<span style=color:#f92672>.</span>settings[<span style=color:#e6db74>&#39;MAX_STATS_PER_WEEK&#39;</span>]:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> Request(self<span style=color:#f92672>.</span>base_url<span style=color:#f92672>.</span>format(self<span style=color:#f92672>.</span>settings[<span style=color:#e6db74>&#39;YAHOO_LEAGUEID&#39;</span>], current_week <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>), callback<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>parse_stats)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> Request(next_page_url, callback<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>parse_stats)</span></span></code></pre></div></li><li><strong>XPath expressions</strong>: In the past, I'd use either BeautifulSoup or PyQuery to traverse the DOM but found XPath expressions to be simpler. There’s less code to write and the expressions are easier to understand and have a higher information density.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>stat_rows <span style=color:#f92672>=</span> hxs<span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#39;//table[@id=&#34;statTable0&#34;]/tbody/tr&#39;</span>)
</span></span><span style=display:flex><span>xpath_map <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;name&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;player&#34;)]/div[contains(@class,&#34;ysf-player-name&#34;)]/a/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;position&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;player&#34;)]/div[contains(@class,&#34;ysf-player-detail&#34;)]/ul/li[contains(@class,&#34;ysf-player-team-pos&#34;)]/span/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;opp&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;opp&#34;)]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;passing_yds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][1]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;passing_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][2]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;passing_int&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][3]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;rushing_yds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][4]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;rushing_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][5]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;receiving_recs&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][6]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;receiving_yds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][7]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;receiving_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][8]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;return_tds&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][9]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;misc_twopt&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][10]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;fumbles&#39;</span>: <span style=color:#e6db74>&#39;td[@class=&#34;stat&#34;][11]/text()&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;points&#39;</span>: <span style=color:#e6db74>&#39;td[contains(@class,&#34;pts&#34;)]/text()&#39;</span>,
</span></span><span style=display:flex><span>}</span></span></code></pre></div></li></ul><p>This also got me thinking about the evolution of my approach to scraping. In 2006, I was into Perl and scraped using the LWP::Simple, WWW::Mechanize and the HTML::TreeBuilder libraries. After I moved on to Python I switched to using urllib and BeautifulSoup. Most recently, I’ve started using the wonderful requests library along with PyQuery. Conceptually, these approaches are the same: first retrieve a web page and then extract the data you want by traversing the DOM. Scrapy does the same thing internally but by removing a ton of the boilerplate, it lets you focus on the key problems in scraping - figuring out what page to scrape next and figuring out how to extract the content. The rest is handled by Scrapy itself - including file storage, retries, throttling, and probably a ton more that I haven’t gotten a chance to explore yet.</p><p>This also gives me some time to work on the actual draft algorithm. My goal is to create a strategy that’s using a value based approach combined with my schedule. The idea is that I shouldn’t pick the players that will have the highest point total over the season but the ones that will have more points during my tough matchups. Of course, it’s almost all luck but I’m still looking forward to attempting this approach.</p></div><div class=navigation><div class=row><div class="col-12 col-lg-6"><div class="mx-0 mx-md-4 mt-4 text-left"><a href=/2013/07/13/marketplaces-are-hard/>« Marketplaces are hard</a></div></div><div class="col-12 col-lg-6"><div class="mx-0 mx-md-4 mt-4 text-right"><a href=/2013/07/21/beware-the-data-monopoly/>Beware the data monopoly »</a></div></div></div></div></div></div></div></div><section id=comments><div class="py-3 content"><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-lg-8"><div class=comments><script src=https://utteranc.es/client.js repo=dangoldin/blog.dangoldin.com-comments issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></div></div></div></div></div></section><div class="my-4 footer"><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-lg-8"><hr></div></div><div class="row justify-content-center"><div class="col-sm-12 col-lg-2"><div class="mx-0 mx-md-4 site-copyright">© 2024 Dan Goldin</div></div><div class="col-sm-12 col-lg-6"><div class="mx-0 mx-md-4 site-social"><ul><li><a href=mailto:dan@dangoldin.com>Contact</a></li><li><a href=https://github.com/dangoldin target=_blank>GitHub</a></li><li><a href=https://twitter.com/dangoldin target=_blank>Twitter</a></li><li><a href=https://www.linkedin.com/in/dangoldin target=_blank>LinkedIn</a></li></ul></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js defer></script><script>window.addEventListener("load",function(){hljs.initHighlighting()},!0)</script></body></html>